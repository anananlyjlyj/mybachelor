{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The old lighthouse keeper and the sea\n",
    "\n",
    "In a Scottish pub you meet a retired lighthouse keeper who is telling about the lighthouse, situated at position $(x_0,y_0)$ miles of the coast (see ﬁgure) that he had been tending before retirement. The lighthouse is peculiar: instead of emitting a periodic signal in a given direction it emits short, focused light pulses randomly in every horizontal direction (or azimuth). No direction is preferred, and no correlation exists among the directions of the ﬂashes. Since you got curious you take a walk along the coast, and you record your location when observing a ﬂash. (see the recorded measurements in ﬁle _lighthouse.dat_) Now you want to infer the position of the lighthouse, given only the various positions of the light signal recordings. Since we want to restrict ourselves to a 1-parameter problem for this exercise, you can assume the $x_0$ coordinate of the lighthouse to be 1.25 miles.\n",
    "\n",
    "* a: Translate the probability density distribution of the azimuth $θ$ of the ﬂashes into a probability density for observing a ﬂash at location $x$. Hint: Applying simple trigonometry, relate the angle to position along the coast. Note, that the question has nothing to do with Bayesian estimation as such, it is related to the method of exact transformation between samples drawn from different PDFs.\n",
    "\n",
    "  Since all horizontal direction is equally possible, the PDF of $θ$ can be seen as a uniform distribution in the domain of $[0,2\\pi)$, namely $θ$ ~ $U(0,2\\pi)$ $\\Rightarrow p(θ)=\\chi_{[0,2\\pi)}\\frac{1}{2\\pi}$\n",
    "\n",
    "  According to trigonometry we have $|x_0 - x|= y_0 \\cdot \\tan{θ} \\Rightarrow \\theta = \\arctan{\\frac{|x_0 - x|}{y_0}}$. Because of conservation of probability we get $p(x|y_0)=p(θ)\\lvert{\\frac{dθ}{dx}}\\rvert=\\chi_{[0,2\\pi)}\\frac{1}{2\\pi y_0}\\cdot \\frac{1}{1+(\\frac{|x_0 - x|}{y_0})^2}$ A Cauchy distribution\n",
    "\n",
    "\n",
    "* b: Late during the very evening in the pub the lighthouse keeper tells stories of the early days when he in fact had to manually row out to the lighthouse which lies “at least 2miles off shore”. You interpret this statement as a distance of $(2.0±0.3)$ miles distributed like a Gaussian. What is the Bayesian estimate of $y_0$? Compare MAP, mean, and median of the posterior distribution! Compute also $σ_y$!\n",
    "\n",
    "  The likelihood is then a Gaussian $N(2.0, 0.3^2)$: $\\frac{1}{0.3\\sqrt{2\\pi}}e^{-\\frac{(y_0-2.0)^2}{2\\cdot0.3^2}}$\n",
    "  \n",
    "  We assume the prior is: $p(y_0|\\{x_i\\})\\propto \\prod_{x_i}p(x_i|y_0)$\n",
    "  \n",
    "  Thus the posterior is $P(y_0|\\{x_k\\})\\propto \\frac{1}{0.3\\sqrt{2\\pi}}e^{-\\frac{(y_0-2.0)^2}{2\\cdot0.3^2}}\\prod_{x_i}\\chi_{[0,2\\pi)}\\frac{1}{2\\pi y_0}\\cdot \\frac{1}{1+(\\frac{|x_0 - x_i|}{y_0})^2}$\n",
    "  \n",
    "  Calculate MAP: $\\frac{\\partial \\ln{P(y_0|\\{x_k\\})}}{\\partial y_0}=-\\frac{(y_0-2.0)}{0.3^2}-..=0$ $\\Rightarrow$\n",
    "  \n",
    "  Mean: $E(y_0|\\{x_k\\})=\\int_{-\\infty}^{\\infty}{y_0 P(y_0|x)dy_0}=$\n",
    "\n",
    "\n",
    "* c: Comparing the location of the maxima of the likelihood function and posterior, you start to wonder whether the lighthouse keeper did exaggerate the level of hardship of the early days. Redo the the previous estimate with largely uninformative priors ignoring the keeper’s stories: a constant prior and $∝ 1/y$ . What do you get for the MAP distances? What do you conclude?\n",
    "\n",
    "_Hints on the numerical treatment_: since it is a 1D problem one can easily calculate the posterior a sufficiently ﬁne – for simplicity equidistant – grid. A range of y between zero (excluding zero as such) and 3 miles is enough. Then plot the posterior(s). This helps to see what is going on. \n",
    "\n",
    "_Optional add-ons for the tireless ones_: you may try and see what the quadratic approximation would give for $σ_y$. Moreover, you may try to solve the problem by sampling the posterior with a – guess what – Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- read.table(\"lighthouse.dat\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
